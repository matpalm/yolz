{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2dc272dc-fa4f-4ffe-8c5e-18b5964ceb73",
   "metadata": {},
   "source": [
    "# v1.5 embedding model\n",
    "\n",
    "* v1 reproducing constrastive loss for metric learning; (2C, H, W, 3)\n",
    "* v1.5 vectorising that model to operate on average of N embeddings (N, 2C, H, W, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79017548-62c2-4e27-85cc-a68fd8a25ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KERAS_BACKEND'] = 'jax'\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67c87a4-5e25-414f-b3b4-2be157a651f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "import jax\n",
    "from jax import jit, value_and_grad, vmap\n",
    "\n",
    "import optax\n",
    "\n",
    "from keras.layers import Input, Dense, Conv2D, GlobalMaxPooling2D\n",
    "from keras.layers import Layer, BatchNormalization, Activation, Dropout\n",
    "from keras.models import Model\n",
    "\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=5, threshold=10000, suppress=True, linewidth=10000)\n",
    "\n",
    "print('keras', keras.__version__, \n",
    "      'jax', jax.__version__, \n",
    "      'optax', optax.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354e80e4-c9cd-4724-a458-fcb0805f8a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Opts:\n",
    "    height_width = 64\n",
    "    batch_size = 2            # B (outer batch size\n",
    "    num_obj_references = 4    # N number of reference examples given for each object\n",
    "    num_contrastive_objs = 3  # C total number of classes used for contrasting\n",
    "    embedding_dim = 64        # E embedding dim\n",
    "    learning_rate = 1e-4\n",
    "    \n",
    "opts = Opts()\n",
    "\n",
    "def shapes(debug_str, list_of_variables):\n",
    "    return f\"{debug_str} {[v.shape for v in list_of_variables]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9681243f-0f72-47f7-a55d-3118185ab46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting debug\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "def collage(pil_imgs, rows, cols):\n",
    "    n = len(pil_imgs) \n",
    "    if n != rows * cols:\n",
    "        raise Exception()\n",
    "    img_h, img_w = pil_imgs[0].size    \n",
    "    collage = Image.new('RGB', (cols*img_h, rows*img_w))\n",
    "    for i in range(n):\n",
    "        pc, pr = i%rows, i//rows\n",
    "        collage.paste(pil_imgs[i], (pr*img_h, pc*img_w))\n",
    "    return collage\n",
    "    \n",
    "def to_pil_img(a):\n",
    "    a = np.array(a*255, dtype=np.uint8)\n",
    "    return Image.fromarray(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f22e10-db67-4783-aca1-d4b08a7ed85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import ContrastiveExamples, load_fname\n",
    "\n",
    "# start with simple case of  R, G, B examples\n",
    "c_egs = ContrastiveExamples(\n",
    "    root_dir='data/train/reference_patches/',\n",
    "    obj_ids=[\"061\", # \"135\",\"182\",  # x3 red\n",
    "             \"111\", # \"153\",\"198\",  # x3 green\n",
    "             \"000\", #\"017\",\"019\", # x3 blue\n",
    "            ]\n",
    ")\n",
    "ds = c_egs.dataset(num_batches=1,                                   # epoch length\n",
    "                   batch_size=opts.batch_size,                      # B\n",
    "                   num_obj_references=opts.num_obj_references,      # N\n",
    "                   num_contrastive_objs=opts.num_contrastive_objs)  # C\n",
    "for x, y in ds:\n",
    "    break\n",
    "\n",
    "x = jnp.array(x)\n",
    "print(x.shape, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54847fa9-847b-4ec0-a1e3-d631076b08c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recall each element of outer batch is xN examples of anchor/positive pairs\n",
    "collage(\n",
    "    [to_pil_img(x[0,0,0]), \n",
    "     to_pil_img(x[0,0,1])],\n",
    "    rows=1, cols=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683b4ddd-f1de-4357-9ebe-fdfcb2299d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recall each element of outer batch is xN examples of anchor/positive pairs\n",
    "collage(\n",
    "    [to_pil_img(x[0,1,0]), \n",
    "     to_pil_img(x[0,1,1])],\n",
    "    rows=1, cols=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d55b8b-7111-4836-b090-7b9585c13e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recall X.shapee (B=2, N=4, C=6, 64, 64, 3)\n",
    "# to batch from right to left though, we want (B=2, C=6, N=4, 64, 64, 3)\n",
    "x = jnp.transpose(x, (0,2,1,3,4,5))\n",
    "print(x.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476a4075-6a9f-4214-a97e-49f4d04312bc",
   "metadata": {},
   "source": [
    "model is simple enough embedding model\n",
    "\n",
    "output is L2 normalised embedding ( so dot products can be used for sims and xent contrastive )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69673afa-5665-48ae-94e1-0f4dee3d3678",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.models import construct_embedding_model\n",
    "\n",
    "embedding_model = construct_embedding_model(\n",
    "    height_width=64,\n",
    "    filter_sizes=[16,32,64,128],\n",
    "    embedding_dim=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a23c25-7179-4c24-b043-2b42b83ed9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "params = embedding_model.trainable_variables\n",
    "nt_params = embedding_model.non_trainable_variables\n",
    "\n",
    "def mean_embeddings(params, nt_params, x):\n",
    "    # x (N, H, W, 3)\n",
    "    embeddings, nt_params = embedding_model.stateless_call(params, nt_params, x, training=True)  # (N, E)\n",
    "    # average over N\n",
    "    embeddings = jnp.mean(embeddings, axis=0)  # (E)\n",
    "    # (re) L2 normalise\n",
    "    embeddings /= jnp.linalg.norm(embeddings, axis=-1, keepdims=True)\n",
    "    return embeddings, nt_params\n",
    "\n",
    "embeddings, nt_params_2 = mean_embeddings(params, nt_params, x[0,0])\n",
    "\n",
    "print(\"e shape\", embeddings.shape)\n",
    "print(\"e norms\", jnp.linalg.norm(embeddings, axis=-1))\n",
    "print(shapes('ntps', nt_params_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911254bd-bc23-4b86-8f68-a9babaeefec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings, nt_params_2 =  vmap(mean_embeddings, in_axes=(None, None, 0))(params, nt_params, x[0])\n",
    "nt_params_2 = [jnp.mean(p, axis=0) for p in nt_params_2]\n",
    "\n",
    "print(\"e shape\", embeddings.shape)\n",
    "print(\"e norms\", jnp.linalg.norm(embeddings, axis=-1))\n",
    "print(shapes('ntps', nt_params_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fe66e3-4460-438b-bbfd-abac504015c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the constrastive loss based on the 'batch' of 2N examples ( N pairs )\n",
    "\n",
    "def main_diagonal_softmax_cross_entropy(logits):\n",
    "    # cross entropy assuming \"labels\" are just (0, 1, 2, ...) i.e. where\n",
    "    # one_hot mask for log_softmax ends up just being the main diagonal\n",
    "    return -jnp.sum(jnp.diag(jax.nn.log_softmax(logits)))\n",
    "\n",
    "def mean_embeddings(params, nt_params, x):\n",
    "    # x (N, H, W, 3)\n",
    "    embeddings, nt_params = embedding_model.stateless_call(params, nt_params, x, training=True)  # (N, E)\n",
    "    # average over N\n",
    "    embeddings = jnp.mean(embeddings, axis=0)  # (E)\n",
    "    # (re) L2 normalise\n",
    "    embeddings /= jnp.linalg.norm(embeddings, axis=-1, keepdims=True)\n",
    "    return embeddings, nt_params\n",
    "    \n",
    "def constrastive_loss(params, nt_params, x):\n",
    "    # x (2C, N, H, W, 3)\n",
    "    embeddings, nt_params = vmap(mean_embeddings, in_axes=(None, None, 0))(params, nt_params, x)\n",
    "    nt_params = [jnp.mean(p, axis=0) for p in nt_params]\n",
    "    # embeddings (2C, E)    \n",
    "    embeddings = embeddings.reshape((-1, 2, opts.embedding_dim))  # (C, 2, E)\n",
    "    anchors = embeddings[:, 0]\n",
    "    positives = embeddings[:, 1]\n",
    "#    print('anchors', anchors.shape, 'positives', positives.shape)\n",
    "    gram_ish_matrix = jnp.einsum('ae,be->ab', anchors, positives)\n",
    "    xent = main_diagonal_softmax_cross_entropy(logits=gram_ish_matrix)\n",
    "    return jnp.mean(xent), nt_params\n",
    "\n",
    "def batch_constrastive_loss(params, nt_params, x):\n",
    "    losses, nt_params = vmap(constrastive_loss, in_axes=(None, None, 0))(params, nt_params, x)\n",
    "    # x (B, 2C, N, H, W, 3)\n",
    "    nt_params = [jnp.mean(p, axis=0) for p in nt_params]\n",
    "    return jnp.mean(losses), nt_params\n",
    "\n",
    "\n",
    "loss, nt_params_2 = batch_constrastive_loss(params, nt_params, x)\n",
    "print('loss', loss)\n",
    "print(shapes('ntps', nt_params_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b6af92-0972-4097-b134-77f2c030f0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define gradients and a simple training loop\n",
    "\n",
    "def calculate_gradients(params, nt_params, x):\n",
    "    # x (2C,H,W,3)\n",
    "    grad_fn = value_and_grad(constrastive_loss, has_aux=True)    \n",
    "    (loss, nt_params), grads = grad_fn(params, nt_params, x)\n",
    "    return (loss, nt_params), grads\n",
    "\n",
    "opt = optax.adam(learning_rate=opts.learning_rate)\n",
    "\n",
    "def train_step(params, nt_params, opt_state, x):\n",
    "    (loss, nt_params), grads = calculate_gradients(params, nt_params, x)\n",
    "    updates, opt_state = opt.update(grads, opt_state, params)\n",
    "    params = optax.apply_updates(params, updates)\n",
    "    return params, nt_params, opt_state, loss\n",
    "\n",
    "embedding_model = construct_embedding_model()\n",
    "\n",
    "params = embedding_model.trainable_variables\n",
    "nt_params = embedding_model.non_trainable_variables\n",
    "opt_state = opt.init(params)\n",
    "\n",
    "for e in range(1000):\n",
    "    params, nt_params, opt_state, loss = jit(train_step)(params, nt_params, opt_state, x[0])\n",
    "    if e % 100 == 0:\n",
    "        print(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea3b7c9-8bbe-4c88-9c23-b001f4561e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test against batch\n",
    "embeddings, _ = embedding_model.stateless_call(params, nt_params, x[0], training=False)\n",
    "embeddings.shape\n",
    "\n",
    "# looks good (0,1) (2,3) (4,5) all pair well ( and others are -0.5 )\n",
    "jnp.around(jnp.dot(embeddings, embeddings.T), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a27837-0934-4aad-b986-8c94fc3c2b31",
   "metadata": {},
   "source": [
    "next we get things working on a batch of these examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f3d449-ffae-4ce6-918f-62c30c15a6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to use the model batched we vmap it first \n",
    "\n",
    "def training_call(x):\n",
    "    return embedding_model.stateless_call(params, nt_params, x, training=True)\n",
    "\n",
    "training_call = vmap(training_call)\n",
    "embeddings, nt_params_2 = training_call(x)\n",
    "\n",
    "print(\"e shape\", embeddings.shape)\n",
    "print(\"e norms\", jnp.linalg.norm(embeddings, axis=-1))\n",
    "print(shapes('ntps_2', nt_params_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc14ef6-32bd-4cea-9299-e5b91b6634ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# but note that the nt_params returned have been vectorised too\n",
    "# i.e. they are [(B, p1), (B, p2), ...] instead of [(p1,), (p2,), ...]\n",
    "# so, we need to aggreate them,\n",
    "\n",
    "nt_params_2 = [jnp.mean(p, axis=0) for p in nt_params_2]\n",
    "print(shapes('ntps', nt_params_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02de11b1-7182-407c-a6e4-e6c5f8e0c303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# as before we can vectorise the loss \n",
    "# takes (B, 2C, H, W, 3)\n",
    "constrastive_loss_v = vmap(constrastive_loss, in_axes=[None, None, 0])\n",
    "\n",
    "# and run over all of x \n",
    "loss_v, nt_params_2 = constrastive_loss_v(params, nt_params, x)  # (N)\n",
    "\n",
    "print(\"before inner batch aggregation...\")\n",
    "print('loss_v', loss_v)\n",
    "print(shapes('ntps', nt_params_2))\n",
    "\n",
    "loss = jnp.mean(loss_v)\n",
    "nt_params_2 = [jnp.mean(p, axis=0) for p in nt_params_2]\n",
    "\n",
    "print(\"after inner batch aggregation...\")\n",
    "print('loss', loss)\n",
    "print(shapes('ntps', nt_params_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878cbfc8-7ebd-4dbb-beb8-92ab8b7031fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can calculate grads just as before but we must call a function that includes the loss \n",
    "# aggregation ( i.e. grads only are applicable for a scalar loss ) so wrap the vmap\n",
    "# and jnp.mean in one function.\n",
    "\n",
    "def constrastive_loss_v(params, nt_params, x):\n",
    "    # vectorise function as normal\n",
    "    loss_fn_v = vmap(constrastive_loss, in_axes=[None, None, 0])\n",
    "    # call returning vectorised result\n",
    "    loss_v, nt_params_v = loss_fn_v(params, nt_params, x)\n",
    "    # aggregate mean over both loss and nt_params for return\n",
    "    # TODO: what does this do for rng seeds?\n",
    "    loss = jnp.mean(loss_v)\n",
    "    nt_params = [jnp.mean(p, axis=0) for p in nt_params_v]    \n",
    "    return loss, nt_params\n",
    "\n",
    "(loss, nt_params_2), grads = jit(value_and_grad(constrastive_loss_v, has_aux=True))(params, nt_params, x)\n",
    "\n",
    "print('loss', loss)\n",
    "print(shapes('grads', grads))\n",
    "print(shapes('ntps', nt_params_2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b91293-e34f-4341-812f-3d2368fd0640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stitch together into a training loop\n",
    "\n",
    "def main_diagonal_softmax_cross_entropy(logits):\n",
    "    # cross entropy assuming \"labels\" are just (0, 1, 2, ...) i.e. where\n",
    "    # one_hot mask for log_softmax ends up just being the main diagonal\n",
    "    return -jnp.sum(jnp.diag(jax.nn.log_softmax(logits)))\n",
    "    \n",
    "def constrastive_loss(params, nt_params, x):\n",
    "    # x (2C,H,W,3)\n",
    "    embeddings, nt_params = embedding_model.stateless_call(params, nt_params, x, training=True)\n",
    "    embeddings = embeddings.reshape((opts.num_egs_per_class, 2, opts.embedding_dim))\n",
    "    anchors = embeddings[:, 0]\n",
    "    positives = embeddings[:, 1]\n",
    "    gram_ish_matrix = jnp.einsum('ae,be->ab', anchors, positives)\n",
    "    xent = main_diagonal_softmax_cross_entropy(logits=gram_ish_matrix)\n",
    "    return jnp.mean(xent), nt_params\n",
    "\n",
    "def constrastive_loss_v(params, nt_params, x):\n",
    "    # x (B,2C,H,W,3)\n",
    "    loss_fn_v = vmap(constrastive_loss, in_axes=[None, None, 0])\n",
    "    loss_v, nt_params_v = loss_fn_v(params, nt_params, x)\n",
    "    loss = jnp.mean(loss_v)\n",
    "    return loss, nt_params_v\n",
    "\n",
    "def calculate_gradients(params, nt_params, x):\n",
    "    # x (B,2C,H,W,3)\n",
    "    grad_fn = value_and_grad(constrastive_loss_v, has_aux=True)    \n",
    "    (loss, nt_params_v), grads = grad_fn(params, nt_params, x)\n",
    "    return (loss, nt_params_v), grads\n",
    "\n",
    "opt = optax.adam(learning_rate=opts.learning_rate)\n",
    "\n",
    "def train_step(params, nt_params, opt_state, x):\n",
    "    (loss, nt_params_v), grads = calculate_gradients(params, nt_params, x)\n",
    "    updates, opt_state = opt.update(grads, opt_state, params)\n",
    "    params = optax.apply_updates(params, updates)\n",
    "    nt_params = [jnp.mean(p, axis=0) for p in nt_params_v]\n",
    "    return params, nt_params, opt_state, loss\n",
    "\n",
    "embedding_model = construct_embedding_model()\n",
    "\n",
    "params = embedding_model.trainable_variables\n",
    "nt_params = embedding_model.non_trainable_variables\n",
    "opt_state = opt.init(params)\n",
    "\n",
    "for epoch in range(200):\n",
    "    params, nt_params, opt_state, loss = jit(train_step)(params, nt_params, opt_state, x)\n",
    "    if epoch % 20 == 0:\n",
    "        print('e', epoch, 'loss', loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4611475-2611-427d-8661-41eb7dbef8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try a couple of the examples from the batch\n",
    "# each looks good\n",
    "\n",
    "for i in range(3):\n",
    "    print(\"-\"*10, i)\n",
    "    embeddings, _ = embedding_model.stateless_call(params, nt_params, x[i], training=False)\n",
    "    print(jnp.around(jnp.dot(embeddings, embeddings.T), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1206be60-f6e4-45fe-9302-7afce153c5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings, _ = embedding_model.stateless_call(params, nt_params, x[0], training=False)\n",
    "print(jnp.around(jnp.dot(embeddings, embeddings.T), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf3351b-2241-4cea-aef4-417070a3d25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for variable, value in zip(embedding_model.trainable_variables, params):\n",
    "    variable.assign(value)\n",
    "for variable, value in zip(embedding_model.non_trainable_variables, nt_params):\n",
    "    variable.assign(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547a3e62-be55-4e9d-9ce5-ebe92256ac05",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = embedding_model(x[0], training=False)\n",
    "print(jnp.around(jnp.dot(embeddings, embeddings.T), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ffe6c2-9e99-47df-8b50-53aba1e7de0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('test.pkl', 'wb') as f:\n",
    "    pickle.dump(embedding_model.get_weights(), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e58a61d-3701-4142-8e90-bb80e818479d",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model_2 = construct_embedding_model()\n",
    "\n",
    "with open('test.pkl', 'rb') as f:\n",
    "    reloaded_weights = pickle.load(f)\n",
    "embedding_model_2.set_weights(reloaded_weights)\n",
    "\n",
    "embeddings = embedding_model_2(x[0], training=False)\n",
    "print(jnp.around(jnp.dot(embeddings, embeddings.T), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4025a52d-95f2-44b1-8b0f-3917b468e1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245fffbd-f234-417f-b1c4-b00c2c5a0a6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
