{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2dc272dc-fa4f-4ffe-8c5e-18b5964ceb73",
   "metadata": {},
   "source": [
    "# v1 embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79017548-62c2-4e27-85cc-a68fd8a25ade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.5.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ['KERAS_BACKEND'] = 'jax'\n",
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c67c87a4-5e25-414f-b3b4-2be157a651f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "import jax\n",
    "\n",
    "from keras.layers import Input, Dense, Conv2D, GlobalMaxPooling2D\n",
    "from keras.layers import Layer, BatchNormalization, Activation\n",
    "from keras.models import Model\n",
    "\n",
    "from jax import jit, value_and_grad, vmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "354e80e4-c9cd-4724-a458-fcb0805f8a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Opts:\n",
    "    height_width = 64\n",
    "    batch_size = 5          # B\n",
    "    num_classes = 6         # C\n",
    "    num_egs_per_class = 4   # N\n",
    "    embedding_dim = 128     # E\n",
    "    \n",
    "opts = Opts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e6f22e10-db67-4783-aca1-d4b08a7ed85f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.label_idx_to_str {0: '061', 1: '135', 2: '182', 3: '111', 4: '153', 5: '198', 6: '000', 7: '017', 8: '019'}\n",
      "(5, 8, 64, 64, 3) tf.Tensor(\n",
      "[[5 5 7 7 0 0 1 1]\n",
      " [8 8 1 1 0 0 3 3]\n",
      " [6 6 7 7 5 5 4 4]\n",
      " [6 6 3 3 5 5 7 7]\n",
      " [5 5 3 3 1 1 4 4]], shape=(5, 8), dtype=int64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-19 11:45:44.887051: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "from data import ConstrastiveExamples\n",
    "\n",
    "c_egs = ConstrastiveExamples(\n",
    "    root_dir='data/reference_egs',\n",
    "    obj_ids=[\"061\",\"135\",\"182\",  # x3 red\n",
    "             \"111\",\"153\",\"198\",  # x3 green\n",
    "             \"000\",\"017\",\"019\"], # x3 blue\n",
    ")\n",
    "ds = c_egs.dataset(batch_size=opts.batch_size,\n",
    "                   objs_per_batch=opts.num_egs_per_class)\n",
    "for x, y in ds:\n",
    "    print(x.shape, y)\n",
    "\n",
    "x = jnp.array(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3e812617-4ac4-43fb-8b7d-e795703f8a48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_12          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,640</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_13          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_14          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_15          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_max_pooling2d_3          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling2D</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embeddings (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,384</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ l2_normalisation_3              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">L2Normalisation</span>)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_3 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_12 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │           \u001b[38;5;34m448\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_12          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_12 (\u001b[38;5;33mActivation\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_13 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m4,640\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_13          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_13 (\u001b[38;5;33mActivation\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_14 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_14          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_14 (\u001b[38;5;33mActivation\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_15 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_15          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_15 (\u001b[38;5;33mActivation\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_max_pooling2d_3          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalMaxPooling2D\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embeddings (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m16,384\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ l2_normalisation_3              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mL2Normalisation\u001b[0m)               │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">114,784</span> (448.38 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m114,784\u001b[0m (448.38 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">114,304</span> (446.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m114,304\u001b[0m (446.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">480</span> (1.88 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m480\u001b[0m (1.88 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def conv_bn_relu(filters, y):\n",
    "  y = Conv2D(filters=filters, strides=2, kernel_size=3, activation=None, padding='same')(y)\n",
    "  y = BatchNormalization()(y)\n",
    "  return Activation('relu')(y)\n",
    "\n",
    "input = Input((opts.height_width, opts.height_width, 3))\n",
    "y = conv_bn_relu(filters=16, y=input)\n",
    "y = conv_bn_relu(filters=32, y=y)\n",
    "y = conv_bn_relu(filters=64, y=y)\n",
    "y = conv_bn_relu(filters=128, y=y)\n",
    "y = GlobalMaxPooling2D()(y)  # (B, E)\n",
    "\n",
    "class L2Normalisation(Layer):\n",
    "    def call(self, x):\n",
    "        norm = jnp.linalg.norm(x, axis=-1, keepdims=True)\n",
    "        return x / norm\n",
    "\n",
    "# embed, with normalisation\n",
    "embeddings = Dense(\n",
    "    opts.embedding_dim,\n",
    "    use_bias=False,\n",
    "    kernel_initializer=keras.initializers.TruncatedNormal(),\n",
    "    name='embeddings')(y)  # (B, E)\n",
    "embeddings = L2Normalisation()(embeddings)\n",
    "\n",
    "embedding_model = Model(input, embeddings)\n",
    "\n",
    "embedding_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "654991a8-79f3-42b4-9ad3-9cdeb14cab27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<KerasVariable shape=(3, 3, 3, 16), dtype=float32, path=conv2d_12/kernel>,\n",
       "  <KerasVariable shape=(16,), dtype=float32, path=conv2d_12/bias>,\n",
       "  <KerasVariable shape=(16,), dtype=float32, path=batch_normalization_12/gamma>,\n",
       "  <KerasVariable shape=(16,), dtype=float32, path=batch_normalization_12/beta>,\n",
       "  <KerasVariable shape=(3, 3, 16, 32), dtype=float32, path=conv2d_13/kernel>,\n",
       "  <KerasVariable shape=(32,), dtype=float32, path=conv2d_13/bias>,\n",
       "  <KerasVariable shape=(32,), dtype=float32, path=batch_normalization_13/gamma>,\n",
       "  <KerasVariable shape=(32,), dtype=float32, path=batch_normalization_13/beta>,\n",
       "  <KerasVariable shape=(3, 3, 32, 64), dtype=float32, path=conv2d_14/kernel>,\n",
       "  <KerasVariable shape=(64,), dtype=float32, path=conv2d_14/bias>,\n",
       "  <KerasVariable shape=(64,), dtype=float32, path=batch_normalization_14/gamma>,\n",
       "  <KerasVariable shape=(64,), dtype=float32, path=batch_normalization_14/beta>,\n",
       "  <KerasVariable shape=(3, 3, 64, 128), dtype=float32, path=conv2d_15/kernel>,\n",
       "  <KerasVariable shape=(128,), dtype=float32, path=conv2d_15/bias>,\n",
       "  <KerasVariable shape=(128,), dtype=float32, path=batch_normalization_15/gamma>,\n",
       "  <KerasVariable shape=(128,), dtype=float32, path=batch_normalization_15/beta>,\n",
       "  <KerasVariable shape=(128, 128), dtype=float32, path=embeddings/kernel>],\n",
       " [<KerasVariable shape=(16,), dtype=float32, path=batch_normalization_12/moving_mean>,\n",
       "  <KerasVariable shape=(16,), dtype=float32, path=batch_normalization_12/moving_variance>,\n",
       "  <KerasVariable shape=(32,), dtype=float32, path=batch_normalization_13/moving_mean>,\n",
       "  <KerasVariable shape=(32,), dtype=float32, path=batch_normalization_13/moving_variance>,\n",
       "  <KerasVariable shape=(64,), dtype=float32, path=batch_normalization_14/moving_mean>,\n",
       "  <KerasVariable shape=(64,), dtype=float32, path=batch_normalization_14/moving_variance>,\n",
       "  <KerasVariable shape=(128,), dtype=float32, path=batch_normalization_15/moving_mean>,\n",
       "  <KerasVariable shape=(128,), dtype=float32, path=batch_normalization_15/moving_variance>],\n",
       " [(16,), (16,), (32,), (32,), (64,), (64,), (128,), (128,)])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = embedding_model.trainable_variables\n",
    "nt_params = embedding_model.non_trainable_variables\n",
    "\n",
    "params, nt_params, [ntp.shape for ntp in nt_params]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a72a4a37-4c65-4162-96e3-dc239942102f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x[0] (8, 64, 64, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((8, 128),\n",
       " Array([0.99999994, 1.        , 0.99999994, 1.0000001 , 1.        ,\n",
       "        1.        , 1.        , 1.        ], dtype=float32))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"x[0]\", x[0].shape)\n",
    "embeddings = embedding_model(x[0])\n",
    "embeddings.shape, jnp.linalg.norm(embeddings, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f0a23c25-7179-4c24-b043-2b42b83ed9fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e shape (8, 128)\n",
      "e norms [1.         1.         1.         0.99999994 1.         1.\n",
      " 1.         1.        ]\n",
      "ntps [(16,), (16,), (32,), (32,), (64,), (64,), (128,), (128,)]\n"
     ]
    }
   ],
   "source": [
    "# the model sees \"a batch\" as the set of (anchor, positive) pairs\n",
    "# whereas x is a batch of these.\n",
    "\n",
    "embeddings, nt_params_2 = embedding_model.stateless_call(params, nt_params, x[0], training=True)\n",
    "\n",
    "print(\"e shape\", embeddings.shape)\n",
    "print(\"e norms\", jnp.linalg.norm(embeddings, axis=-1))\n",
    "print(\"ntps\", [p.shape for p in nt_params_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "09f3d449-ffae-4ce6-918f-62c30c15a6b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e shape (5, 8, 128)\n",
      "e norms [[0.99999994 1.         1.         0.99999994 1.         1.\n",
      "  1.         1.        ]\n",
      " [0.99999994 1.0000001  1.         1.         1.         1.\n",
      "  1.         1.        ]\n",
      " [1.         1.         1.         0.99999994 1.         1.\n",
      "  0.99999994 1.        ]\n",
      " [0.99999994 1.         1.         1.         1.         0.99999994\n",
      "  1.         1.        ]\n",
      " [1.         0.99999994 1.         1.         0.99999994 1.\n",
      "  1.         1.        ]]\n",
      "ntps [(5, 16), (5, 16), (5, 32), (5, 32), (5, 64), (5, 64), (5, 128), (5, 128)]\n"
     ]
    }
   ],
   "source": [
    "# so to use the model batched we actually need to vmap it first \n",
    "\n",
    "def training_call(x):\n",
    "    return embedding_model.stateless_call(params, nt_params, x, training=True)\n",
    "\n",
    "training_call = vmap(training_call)\n",
    "embeddings, nt_params_2 = training_call(x)\n",
    "\n",
    "print(\"e shape\", embeddings.shape)\n",
    "print(\"e norms\", jnp.linalg.norm(embeddings, axis=-1))\n",
    "print(\"ntps\", [p.shape for p in nt_params_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ddc14ef6-32bd-4cea-9299-e5b91b6634ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ntps [(16,), (16,), (32,), (32,), (64,), (64,), (128,), (128,)]\n"
     ]
    }
   ],
   "source": [
    "# but note that the nt_params returned have been vectorised too\n",
    "# i.e. they are [(B, p1), (B, p2), ...] instead of [(p1,), (p2,), ...]\n",
    "# so, we need to aggreate them,\n",
    "\n",
    "nt_params_2 = [jnp.mean(p, axis=0) for p in nt_params_2]\n",
    "print(\"ntps\", [p.shape for p in nt_params_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "467d8593-9837-4800-99d5-1d896e9b3ea3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array(5.4682417, dtype=float32),\n",
       " [(16,), (16,), (32,), (32,), (64,), (64,), (128,), (128,)])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now onto the constrastive loss,\n",
    "# again first for a 'batch' of examples\n",
    "\n",
    "def main_diagonal_softmax_cross_entropy(logits):\n",
    "    # cross entropy assuming \"labels\" are just (0, 1, 2, ...) i.e. where\n",
    "    # one_hot mask for log_softmax ends up just being the main diagonal\n",
    "    return -jnp.sum(jnp.diag(jax.nn.log_softmax(logits)))\n",
    "    \n",
    "def constrastive_loss(params, nt_params, x):\n",
    "    embeddings, nt_params = embedding_model.stateless_call(params, nt_params, x, training=True)\n",
    "    embeddings = embeddings.reshape((opts.num_egs_per_class, 2, opts.embedding_dim))\n",
    "    anchors = embeddings[:, 0]\n",
    "    positives = embeddings[:, 1]\n",
    "    gram_ish_matrix = jnp.einsum('ae,be->ab', anchors, positives)\n",
    "    xent = main_diagonal_softmax_cross_entropy(logits=gram_ish_matrix)\n",
    "    return jnp.mean(xent), nt_params\n",
    "\n",
    "\n",
    "loss, nt_params_2 = constrastive_loss(params, nt_params, x[0])\n",
    "loss, [ntp.shape for ntp in nt_params_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "02de11b1-7182-407c-a6e4-e6c5f8e0c303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "per_eg_loss [5.4682417 5.4851623 5.500038  5.525987  5.538123 ]\n",
      "ntp [(5, 16), (5, 16), (5, 32), (5, 32), (5, 64), (5, 64), (5, 128), (5, 128)]\n"
     ]
    }
   ],
   "source": [
    "# as before we can vectorise the loss \n",
    "# takes (B, 2C, H, W, 3)\n",
    "constrastive_loss_v = vmap(constrastive_loss, in_axes=[None, None, 0])\n",
    "\n",
    "# and run over all of x \n",
    "per_eg_loss, nt_params_2 = constrastive_loss_v(params, nt_params, x)  # (N)\n",
    "\n",
    "print('per_eg_loss', per_eg_loss)\n",
    "print('ntp', [ntp.shape for ntp in nt_params_2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b9091427-168f-4a17-9dce-df82976afbec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_loss 5.5035105\n",
      "ntp [(16,), (16,), (32,), (32,), (64,), (64,), (128,), (128,)]\n"
     ]
    }
   ],
   "source": [
    "# and, as before, we need to aggregate everythging\n",
    "\n",
    "avg_loss = jnp.mean(per_eg_loss)\n",
    "nt_params_2 = [jnp.mean(p, axis=0) for p in nt_params_2]\n",
    "\n",
    "print('avg_loss', avg_loss)\n",
    "print('ntp', [ntp.shape for ntp in nt_params_2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
